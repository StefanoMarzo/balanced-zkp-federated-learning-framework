{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f2c68e",
   "metadata": {},
   "source": [
    "### Imports & Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc23df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nn_model as nn\n",
    "from utils import *\n",
    "from utils import properties as p\n",
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "from metrics import *\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ba910b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from noknow.core import ZK, ZKSignature, ZKParameters, ZKData, ZKProof\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ca69a3",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ab0922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_n = 1\n",
    "learning_rate = 0.1\n",
    "seed = 19101995\n",
    "\n",
    "features = {\n",
    "    'ETHNICITY': ['Asian', 'Black', 'Indian', 'White'],\n",
    "    'GENDER': ['Female', 'Male']\n",
    "}\n",
    "\n",
    "not_features = {\n",
    "    'ETHNICITY': ['ROCK', 'PAPER', 'SCISSORS', 'UNCATEGORIZED'],\n",
    "    'GENDER': ['ZERO', 'ONE']\n",
    "}\n",
    "\n",
    "p.update({\n",
    "    \n",
    "    #Age range\n",
    "    'age_min' : 0,\n",
    "    'age_max' : 39,\n",
    "    \n",
    "    #Number of data samples\n",
    "    'data_samples' : 10000,\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2d8803",
   "metadata": {},
   "source": [
    "### ZKP Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8576c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZKServer:\n",
    "    def __init__(self, password, features):\n",
    "        self.password = password\n",
    "        self.features = features\n",
    "        self.client_representations = {}\n",
    "        self.tokens = {}\n",
    "        self.initialized_zk_features = False\n",
    "        \n",
    "        for el in features:\n",
    "            self.client_representations[el] = []\n",
    "            self.tokens[el] = []\n",
    "        self.zk = ZK.new(curve_name=\"secp384r1\", hash_alg=\"sha3_512\")\n",
    "        self.signature: ZKSignature = self.zk.create_signature(password)\n",
    "            \n",
    "        self.groups = {}\n",
    "        for f in self.features:\n",
    "            self.groups[f] = Counter()\n",
    "            \n",
    "    def load_client_signature(self, signature):\n",
    "        #load client signature\n",
    "        client_signature = ZKSignature.load(signature)\n",
    "        return ZK(client_signature.params)\n",
    "    \n",
    "    def create_token(self, feature, signature):\n",
    "        #load client signature\n",
    "        client_signature = ZKSignature.load(signature)\n",
    "        client_zk = ZK(client_signature.params)\n",
    "        # Create a signed token and send to the client\n",
    "        token = self.zk.sign(self.password, client_zk.token()).dump(separator=\":\")\n",
    "        self.tokens[feature] += [token]\n",
    "        self.client_representations[feature] += [{'signature' : client_signature, 'zk' : client_zk}]\n",
    "        assert token in self.tokens[feature]\n",
    "        return token\n",
    "        \n",
    "    def verify_clients(self, feature, signature):\n",
    "        # Get the token from the client\n",
    "        proof = ZKData.load(signature)\n",
    "        token = ZKData.load(proof.data, \":\")\n",
    "        \n",
    "        proofs = []\n",
    "        # In this example, the server signs the token so it can be sure it has not been modified\n",
    "        for label in self.client_representations[feature]:\n",
    "            client_signature = label['signature']\n",
    "            client_zk = label['zk']\n",
    "            proofs += [self.verify_client(proof, token, client_signature, client_zk)]\n",
    "            \n",
    "        return sum(proofs) >= 1\n",
    "    \n",
    "    def verify_client(self, proof, token, client_signature, client_zk):\n",
    "        return self.zk.verify(token, self.signature) and \\\n",
    "                client_zk.verify(proof, client_signature, data=token)\n",
    "    \n",
    "    def verify(self, feature, signatures):\n",
    "        return sum([self.verify_clients(feature, s) for s in signatures]) >= 1\n",
    "    \n",
    "    def get_features_permutation(self):\n",
    "        balanced = []\n",
    "        for f in self.encrypted_features_dict:\n",
    "            balanced += [self.encrypted_features_dict[f]]\n",
    "        return list(itertools.product(*balanced))\n",
    "    \n",
    "    def init_zk(self, clients):\n",
    "        if self.initialized_zk_features:\n",
    "            print('Server already initialized')\n",
    "            return\n",
    "        \n",
    "        feature_dict = {}\n",
    "        \n",
    "        for c in clients:\n",
    "            self.create_token(c.feature, c.signature)\n",
    "            \n",
    "            if c.feature not in feature_dict:\n",
    "                feature_dict[c.feature] = [{'feature': c.feature, 'label': c.encrypt_label()}]\n",
    "            else:\n",
    "                feature_dict[c.feature] += [{'feature': c.feature, 'label': c.encrypt_label()}]\n",
    "        \n",
    "        self.encrypted_features_dict = feature_dict\n",
    "        \n",
    "        permutations = self.get_features_permutation()\n",
    "                \n",
    "        for individual in permutations:\n",
    "            for feat in individual:\n",
    "                self.groups[feat['feature']].update({feat['label']: 1})\n",
    "        self.initialized_zk_features = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2bdd006",
   "metadata": {},
   "source": [
    "### ZKP Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35cbaaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZKClient:\n",
    "    def __init__(self, feature, label):\n",
    "        self.zk = ZK.new(curve_name=\"secp256k1\", hash_alg=\"sha3_256\")\n",
    "        self.label = label\n",
    "        self.feature = feature\n",
    "        # Create signature and send to server\n",
    "        self.signature = self.zk.create_signature(label).dump()\n",
    "        \n",
    "    def set_label(self, label):\n",
    "        self.label = label\n",
    "        self.signature = self.zk.create_signature(label).dump()\n",
    "            \n",
    "    def create_proof(self, server_token):\n",
    "        # Create a proof that signs the provided token and sends to server\n",
    "        proof = self.zk.sign(self.label, server_token).dump()\n",
    "        return proof\n",
    "    \n",
    "    def create_proofs(self, server_tokens):\n",
    "        return [self.create_proof(t) for t in server_tokens]\n",
    "    \n",
    "    def encrypt_label(self, encrypt=True):\n",
    "        #Create a secret hash\n",
    "        secret = hashlib.sha256()\n",
    "        #use the zk client salt value to encrypt the string\n",
    "        encrypted_label = self.label + str(self.zk.params.s)\n",
    "        #create the hash\n",
    "        secret.update(encrypted_label.encode('utf-8'))\n",
    "        \n",
    "        if encrypt:\n",
    "            return secret.hexdigest()\n",
    "        else:\n",
    "            return self.label #TESTING ONLY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d16ff22",
   "metadata": {},
   "source": [
    "### Server Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61d946e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ServerInitializer:\n",
    "    def __init__(self, features, client_prototype):\n",
    "        self.client_prototype = client_prototype\n",
    "        self.features = features\n",
    "        \n",
    "    def create_clients(self):\n",
    "        clients = []\n",
    "        for feature in self.features:\n",
    "            for label in self.features[feature]:\n",
    "                client = copy.copy(self.client_prototype)\n",
    "                client.feature = feature\n",
    "                client.set_label(label)\n",
    "                clients += [client]\n",
    "        return clients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9529541c",
   "metadata": {},
   "source": [
    "### Client Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f69c06df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClientInitializer:\n",
    "    def __init__(self):\n",
    "        self.generated = False\n",
    "    def generate_client_prototype(self):\n",
    "        if not self.generated:\n",
    "            self.generated = True\n",
    "            return ZKClient('', '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eaa8809",
   "metadata": {},
   "source": [
    "### Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a28b8281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Server \n",
    "class FairServer(ZKServer):\n",
    "    def __init__(self, password, features, model, max_gap, gap, self_balancing=True):\n",
    "        super().__init__(password, features)\n",
    "        self.self_balancing = self_balancing\n",
    "        self.model = LearningModel(model)\n",
    "        self.workers = []\n",
    "        self.queue = {}\n",
    "        self.max_gap = max_gap\n",
    "        self.gap = gap\n",
    "        \n",
    "        \n",
    "    def register_worker(self, worker):\n",
    "        if self.zk_authenticate(worker):\n",
    "            self.workers += [worker]\n",
    "        \n",
    "    def register_feature_group(self, feature, label):\n",
    "        self.groups[feature].update({label : 1})\n",
    "\n",
    "    def is_balanced(self, feature, label):\n",
    "        if len(self.groups[feature]) == 0:\n",
    "            return True\n",
    "        count = sum(count for n, count in self.groups[feature].items())\n",
    "        avg = count / len(self.groups[feature])\n",
    "        calc_gap = (self.groups[feature][label] + 1) - avg\n",
    "        #print(calc_gap/avg, calc_gap)\n",
    "        return (calc_gap / avg) <= self.gap or calc_gap <= self.max_gap\n",
    "    \n",
    "    def send_model(self, worker):\n",
    "        worker.load_model(self.model)\n",
    "        \n",
    "    def balanced_update(self, features):\n",
    "        #if self balancin is disabled return true\n",
    "        if not self.self_balancing:\n",
    "            return True\n",
    "        \n",
    "        return len(features) == sum([\n",
    "            self.is_balanced(list(f.keys())[0], list(f.values())[0])\n",
    "            for f \n",
    "            in features\n",
    "        ])\n",
    "    \n",
    "    def get_features_key_values(self, f):\n",
    "        return list(f.keys())[0], list(f.values())[0]\n",
    "        \n",
    "    def enqueue_worker(self, w_id, features):\n",
    "        labels = 0\n",
    "        for f in features: \n",
    "            k, v = self.get_features_key_values(f)\n",
    "            labels += int(v, 16) #hex\n",
    "        if str(labels) not in self.queue:\n",
    "            self.queue[str(labels)] = [w_id]\n",
    "        else:\n",
    "            self.queue[str(labels)] += [w_id]\n",
    "    \n",
    "    def load_update(self, w_id, features, weights):\n",
    "        if not self.balanced_update(features):\n",
    "            #print('Unbalanced id: ' + str(w_id))\n",
    "            self.enqueue_worker(w_id, features)\n",
    "            return\n",
    "        for f in features:\n",
    "            k, v = self.get_features_key_values(f)\n",
    "            self.register_feature_group(k, v)\n",
    "        self.model.set_weights(weights)\n",
    "        \n",
    "    def request_training(self, w):\n",
    "        w.train()\n",
    "        \n",
    "    def zk_authenticate(self, w):\n",
    "        #ZKP Authentication\n",
    "        verification = [\n",
    "            self.verify_clients(f, w.zkp_clients[f].create_proof(self.tokens[f][0]))\n",
    "            for f in self.features                                    \n",
    "        ]\n",
    "        auth = sum(verification) == len(self.features)\n",
    "        #print(('' if auth else 'Un') + 'authorized')\n",
    "        return auth\n",
    "    \n",
    "    def get_next_possible_updates(self):\n",
    "        possible = []\n",
    "        permutation = self.get_features_permutation()\n",
    "        for individual in permutation:\n",
    "            bal = [self.is_balanced(feat['feature'], feat['label']) for feat in individual]\n",
    "            if False not in bal:\n",
    "                possible += [individual]\n",
    "        return possible\n",
    "    \n",
    "    def get_possible_queues(self):\n",
    "        possible_updates = self.get_next_possible_updates()\n",
    "        queue_ids = []\n",
    "        for individual in possible_updates:\n",
    "            queue_ids += [str(sum([int(feat['label'], 16) for feat in individual]))]\n",
    "        return queue_ids\n",
    "    \n",
    "    def get_possible_workers(self):\n",
    "        q_ids = self.get_possible_queues()\n",
    "        possible_ids = [\n",
    "            q_id \n",
    "            for q_id in q_ids \n",
    "            if q_id in self.queue and len(self.queue[q_id]) != 0\n",
    "        ]\n",
    "        return self.queue[possible_ids[0]] if len(possible_ids) != 0 else []\n",
    "    \n",
    "    def get_worker(self, w_id):\n",
    "        return next(filter(lambda w: w.id == w_id, self.workers))\n",
    "    \n",
    "    def train(self):\n",
    "        #Sequential train of workers\n",
    "        for w in self.workers:\n",
    "            self.send_model(w)\n",
    "            self.request_training(w)\n",
    "        \n",
    "        #Balance the rest of the workers\n",
    "        possible_workers = self.get_possible_workers()\n",
    "        while len(possible_workers) != 0:\n",
    "            w_id = possible_workers.pop()\n",
    "            w = self.get_worker(w_id)\n",
    "            self.send_model(w)\n",
    "            self.request_training(w)\n",
    "            possible_workers = self.get_possible_workers()\n",
    "        \n",
    "    def fair_metrics(self):\n",
    "        return 'Fair metrics: '\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def plot_hist(self, feature):\n",
    "        plt.title(feature)\n",
    "        x = np.arange(len(self.groups[feature]))\n",
    "        y = [self.groups[feature][value] for value in self.groups[feature]]\n",
    "        plt.bar(x, height=y)\n",
    "        plt.xticks([])\n",
    "        plt.ylabel(\"Probability\")\n",
    "        plt.xlabel(\"Data\")\n",
    "        plt.show()\n",
    "        \n",
    "    def count_updates(self):\n",
    "        if len(self.features) <= 0:\n",
    "            return 0\n",
    "        return sum(self.features[list(self.features.keys())[0]])\n",
    "        \n",
    "        \n",
    "        \n",
    "    def plot_hists(self, name):\n",
    "        fig, axs = plt.subplots(\n",
    "            1, len(self.features), \n",
    "            sharey=True, tight_layout=True, \n",
    "            figsize=(8, 4)\n",
    "        )\n",
    "        \n",
    "        for f, i in zip(self.features.keys(), range(len(self.features))):\n",
    "            axs[i].title.set_text(f)\n",
    "            x = np.arange(len(self.groups[f]))\n",
    "            y = [self.groups[f][value] for value in self.groups[f]]\n",
    "            axs[i].bar(x, height=y)\n",
    "            axs[i].set_xticks([], minor=False)\n",
    "            axs[i].set_ylabel(\"Probability\")\n",
    "            axs[i].set_xlabel(\"Data\")\n",
    "            s = sum(y)\n",
    "            \n",
    "        fig.suptitle(name + f', #records: {s}')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8152a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Worker \n",
    "class Worker:\n",
    "    #secret_features must of the form {'f_name_1': 'f_value_1', 'f_name_2': 'f_value_2', ...}\n",
    "    def __init__(self, id_w, zkp_client_prototype, server, x, y, secret_features, encrypt=True):\n",
    "        self.id = id_w\n",
    "        self.zkp_client_prototype = zkp_client_prototype\n",
    "        self.server = server\n",
    "        self.model = {}\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.secret_features = secret_features\n",
    "        self.encrypt = encrypt\n",
    "        self.zkp_clients = {}\n",
    "        for f in secret_features.keys():\n",
    "            c = copy.copy(zkp_client_prototype)\n",
    "            c.feature = f\n",
    "            c.set_label(secret_features[f])\n",
    "            self.zkp_clients[f] = c\n",
    "        \n",
    "    def send_registration(self):\n",
    "        self.server.register_worker(self)\n",
    "        \n",
    "    def prepare_features(self):\n",
    "        feature_to_send = []\n",
    "        for k in self.zkp_clients.keys():\n",
    "            c = self.zkp_clients[k]\n",
    "            secret = c.encrypt_label(self.encrypt)\n",
    "            feature_to_send += [{c.feature: secret}]\n",
    "        return feature_to_send\n",
    "                    \n",
    "    def load_model(self, model):\n",
    "        self.model = model\n",
    "        \n",
    "    def send_update(self, features, weights):\n",
    "        self.server.load_update(self.id, features, weights)\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.train(self.x, self.y)\n",
    "        features = self.prepare_features()\n",
    "        weights = self.model.get_weights()\n",
    "        self.send_update(features, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fde08773",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningModel:\n",
    "    def __init__(self, model, epochs=epochs_n, learning_rate=learning_rate):\n",
    "        self.model = model\n",
    "        self.epochs = epochs\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def set_weights(self, W):\n",
    "        self.model.load_weights(W)\n",
    "        \n",
    "    def get_weights(self):\n",
    "        return self.model.get_weights()\n",
    "    \n",
    "    def train(self, X, y):\n",
    "        self.model.fit(X, y, self.epochs, self.learning_rate)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f94fd7",
   "metadata": {},
   "source": [
    "### ZKP-FED-Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76196faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZKPFEDFramework:\n",
    "    def __init__(self, features, not_features, gap=0.05, max_gap=5, data=[], self_balancing=True):\n",
    "        self.self_balancing = self_balancing\n",
    "        self.client_prototype = ClientInitializer().generate_client_prototype()\n",
    "        self.features = features\n",
    "        self.not_features = not_features #TESTING\n",
    "        self.server_initializer = ServerInitializer(features, self.client_prototype)\n",
    "        self.gap = gap\n",
    "        self.max_gap = max_gap\n",
    "\n",
    "        #self.test_server()\n",
    "        \n",
    "        \n",
    "    #ZKP Assertions\n",
    "    def test_server(self):\n",
    "        #Create a mock server initializer with actual features\n",
    "        si_f = ServerInitializer(self.features, self.client_prototype)\n",
    "        \n",
    "        #Create a mock server initializer with unauthorized features (not_features)\n",
    "        si_n = ServerInitializer(self.not_features, self.client_prototype)\n",
    "        \n",
    "        #Create a mock server\n",
    "        server = ZKServer('password', features)\n",
    "        \n",
    "        #Register authrized clients in the mock server\n",
    "        server.init_zk(si_f.create_clients())\n",
    "        \n",
    "        #Create proofs for authorized users\n",
    "        mock_clients_f = si_f.create_clients()\n",
    "        proofs_f = [server.verify(c.feature, c.create_proofs(server.tokens[c.feature])) \n",
    "                  for c \n",
    "                  in mock_clients_f]\n",
    "        \n",
    "        #Create proofs for unauthorized users\n",
    "        mock_clients_n = si_n.create_clients()\n",
    "        proofs_n = [server.verify_clients(c.feature, c.create_proof(server.tokens[c.feature][0])) \n",
    "                  for c \n",
    "                  in mock_clients_n]\n",
    "        \n",
    "        #Assert that all the registered clients get access to the server\n",
    "        assert sum(proofs_f) == len(mock_clients_f)\n",
    "        \n",
    "        #Assert that none of the non-registered clients get access to the server\n",
    "        assert sum(proofs_n) == 0\n",
    "        \n",
    "    #Create a server\n",
    "    def create_server(self, model):\n",
    "        fs = FairServer('password', features, model, gap=self.gap, max_gap=self.max_gap, self_balancing=self.self_balancing)\n",
    "        fs.init_zk(self.server_initializer.create_clients())\n",
    "        return fs\n",
    "    \n",
    "    #Create workers\n",
    "    def create_workers(self, server, X, y, secret_features):\n",
    "        return [Worker(i, self.client_prototype, server, X[i], y[i], secret_features[i]) for i in range(len(X))]\n",
    "\n",
    "    #Register all workers\n",
    "    def register_workers(self, workers):\n",
    "        for worker in workers:\n",
    "            worker.send_registration()\n",
    "\n",
    "    def start_training(self, server):\n",
    "        start_train = time.time()\n",
    "        server.train()\n",
    "        end_train = time.time()\n",
    "        #print('Training time:' + str(end_train - start_train))\n",
    "\n",
    "    def zkp_fed_training(self, model, X, y, secret):\n",
    "        s = self.create_server(model)\n",
    "        ws = self.create_workers(s, X, y, secret)\n",
    "        self.register_workers(ws)\n",
    "        self.start_training(s)\n",
    "        #print(s.fair_metrics())\n",
    "        return s#, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bf376c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35a7776",
   "metadata": {},
   "source": [
    "### Model for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7356e632",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_fact = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d509354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# network (not federated)\n",
    "net = nn.get_3l_nn(2, 2, 1)\n",
    "\n",
    "X = np.array([[[[0, 0]]], [[[0, 1]]], [[[1, 0]]], [[[1, 1]]]] * mult_fact)\n",
    "y = np.array([[[[0]]], [[[1]]], [[[1]]], [[[0]]]] * mult_fact)\n",
    "\n",
    "#train\n",
    "for i in range(len(X)):\n",
    "    net.fit(X[i], y[i], epochs=epochs_n, learning_rate=learning_rate)\n",
    "\n",
    "# test\n",
    "out = net.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620b319b",
   "metadata": {},
   "source": [
    "### Model for Fed-Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12deb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[[[0, 0]]], [[[0, 1]]], [[[1, 0]]], [[[1, 1]]], [[[1, 2]]]] * mult_fact)\n",
    "y = np.array([[[[0]]], [[[1]]], [[[1]]], [[[0]]], [[[2]]]] * mult_fact)\n",
    "\n",
    "zkp_fed_framework = ZKPFEDFramework(features, not_features, gap=100, max_gap=mult_fact*100)\n",
    "# network (for federated learning)\n",
    "net2 = nn.get_3l_nn(2, 2, 1)\n",
    "\n",
    "feature_groups = [\n",
    "    {\n",
    "        'ETHNICITY': get_rnd_ethnicity(),\n",
    "        'GENDER': get_rnd_gender()\n",
    "    } for _ in range(int(len(X)/mult_fact) - 1)] + [\n",
    "    {\n",
    "        'ETHNICITY': 'unauthorized',\n",
    "        'GENDER': get_rnd_gender()\n",
    "    }\n",
    "]\n",
    "\n",
    "feature_groups *= mult_fact\n",
    "\n",
    "#train\n",
    "#s = zkp_fed_framework.zkp_fed_training(net2, X, y, feature_groups)\n",
    "\n",
    "#test\n",
    "#out2 = s.predict([w.x for w in s.workers])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba23383c",
   "metadata": {},
   "source": [
    "### Test if the 2 models behave in the same way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae0c1847",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assert np.array_equal(out, out2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dfa0f5",
   "metadata": {},
   "source": [
    "### Test if workers retain features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1fc9220d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_features(z_fed):\n",
    "    w_groups = [w.secret_features for w in z_fed.s.workers] \n",
    "    test_groups = {}\n",
    "\n",
    "    salt = z_fed.client_prototype.zk.params.s\n",
    "\n",
    "    for f in features:\n",
    "        test_groups[f] = Counter()\n",
    "\n",
    "    for t in w_groups:\n",
    "        for f in t.keys():\n",
    "            secret = hashlib.sha256()\n",
    "            label = t[f] + str(salt)\n",
    "            secret.update(label.encode('utf-8'))\n",
    "            label = secret.hexdigest()\n",
    "            test_groups[f].update({label : 1})\n",
    "\n",
    "    #check if the two counters are equal\n",
    "    assert test_groups == z_fed.s.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a5b055",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321abb74",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61df54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../dataset/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de0769",
   "metadata": {},
   "source": [
    "### Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "40134bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove other ethnicities\n",
    "del p['ETHNICITIES'][4]\n",
    "df = df[df['ethnicity'] != 4]\n",
    "#print_summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14cdb9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_filter(df, age_min, age_max):\n",
    "    return (df['age'] >= age_min) & (df['age'] <= age_max)\n",
    "\n",
    "def ethnicity_gender_filter(df, i, j):\n",
    "    return (df['ethnicity'] == p['ETHNICITIES'][i]) & (df['gender'] == p['GENDERS'][j])\n",
    "\n",
    "def ethnicity_age_filter(df, e, age_min, age_max):\n",
    "    return (df['ethnicity'] == p['ETHNICITIES'][e]) & age_filter(df, age_min, age_max)\n",
    "\n",
    "def ethnicity_gender_age_filter(df, i, j, age_min, age_max):\n",
    "    return ethnicity_gender_filter(df, i, j) & age_filter(df, age_min, age_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cc5c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare\n",
    "df = df.loc[age_filter(df, p['age_min'], p['age_max'])]\n",
    "df['ethnicity'] = df['ethnicity'].map(p['ETHNICITIES'])\n",
    "df['gender'] = df['gender'].map(p['GENDERS'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faae2505",
   "metadata": {},
   "source": [
    "### Create balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba56454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ethnicity gender age sample size\n",
    "ethnicity_age_sample_size = round(p['data_samples'] / (round(p['age_range']() / p['age_bins']) * len(p['ETHNICITIES'])))\n",
    "\n",
    "balanced_df = pd.concat([\n",
    "    df.loc[ethnicity_age_filter(df, e, age_m, age_M)]\\\n",
    "        .sample(ethnicity_age_sample_size, random_state=p['seed'], replace=True)\n",
    "    for e in range(len(p['ETHNICITIES']))\n",
    "    #for j in range(len(GENDERS))\n",
    "    for (age_m, age_M) in p['bins']()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840171f6",
   "metadata": {},
   "source": [
    "### Create imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e608ab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_unbalanced_set(df, minority_proportion=0.05, majority_group=0):\n",
    "    min_factor = minority_proportion # 5% of the population \n",
    "    maj_factor = 1 - min_factor\n",
    "\n",
    "    #Size of minority group\n",
    "    min_sample_size = round(p['data_samples'] * min_factor / len(p['bins']()) / (len(p['ETHNICITIES']) - 1))\n",
    "\n",
    "    #Size of majority group\n",
    "    maj_sample_size = round(p['data_samples'] * maj_factor / len(p['GENDERS']) / len(p['bins']()))\n",
    "\n",
    "    maj_male = pd.concat([\n",
    "        df.loc[ethnicity_gender_age_filter(df, majority_group, 0, age_min, age_max)]\\\n",
    "            .sample(maj_sample_size, random_state=p['seed'], replace=True)\n",
    "        for (age_min, age_max) in p['bins']()\n",
    "    ])\n",
    "\n",
    "    maj_female = pd.concat([\n",
    "        df.loc[ethnicity_gender_age_filter(df, majority_group, 1, age_min, age_max)]\\\n",
    "            .sample(maj_sample_size, random_state=p['seed'], replace=True)\n",
    "        for (age_min, age_max) in p['bins']()\n",
    "    ])\n",
    "\n",
    "    unbalanced_df = pd.concat([\n",
    "        df.loc[ethnicity_age_filter(df, e, age_min, age_max)]\\\n",
    "            .sample(min_sample_size, random_state=p['seed'], replace=True)\n",
    "        for e in range(len(p['ETHNICITIES']))\n",
    "        #for j in range(len(GENDERS))\n",
    "        for (age_min, age_max) in p['bins']()\n",
    "        if e != majority_group\n",
    "    ] + [maj_female, maj_male])\n",
    "    \n",
    "    return unbalanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c511b84",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3e327f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_nn():\n",
    "    return nn.get_standard_nn(p['seed'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e49efdb",
   "metadata": {},
   "source": [
    "### Evaluate predictive models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "65f815eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_ethnicity(dataset, ethnicity, df_test, model):\n",
    "    idx_keys = dataset.index.intersection(df_test[df_test['ethnicity'] == ethnicity].index)\n",
    "    ethn_df = dataset.loc[idx_keys]\n",
    "    ethn_X = prepare_X(ethn_df)\n",
    "    ethn_y = prepare_y(ethn_df)\n",
    "    ethn_y_pred = model.predict(ethn_X)\n",
    "    score = f1_score(convert_output(ethn_y), convert_output(ethn_y_pred), average='macro')\n",
    "    return score\n",
    "\n",
    "def evaluate_all_ethnicities(dataset, df_test, model):\n",
    "    scores = [evaluate_ethnicity(dataset, e, df_test, model) for e in p['ETHNICITIES'].values()]\n",
    "    return dict(zip(p['ETHNICITIES'].values(), scores))\n",
    "\n",
    "def get_ethnicity_predictions(dataset, df_test, ethnicity, model):\n",
    "    idx_keys = dataset.index.intersection(df_test[df_test['ethnicity'] == ethnicity].index)\n",
    "    ethn_df = dataset.loc[idx_keys]\n",
    "    ethn_X = prepare_X(ethn_df)\n",
    "    ethn_y = prepare_y(ethn_df)         #y_true \n",
    "    ethn_y_pred = model.predict(ethn_X) #y_pred \n",
    "    return ethn_y, ethn_y_pred\n",
    "\n",
    "def ethnicity_equality_metric(\n",
    "    dataset, \n",
    "    df_test, \n",
    "    ethnicity, \n",
    "    model, \n",
    "    privileged_group, \n",
    "    ethn_y_p, \n",
    "    ethn_y_p_pred, \n",
    "    metric_fun):\n",
    "    if ethnicity == privileged_group:\n",
    "        return 0\n",
    "    \n",
    "    ethn_y_u, ethn_y_u_pred = get_ethnicity_predictions(dataset, df_test, ethnicity, model) #unprivileged\n",
    "    \n",
    "    #print(ethn_y_u, ethn_y_u, ethn_y_u_pred, ethnicity)\n",
    "    \n",
    "    return np.nanmean(metric_fun(\n",
    "        one_hot_vect_to_class(convert_output(ethn_y_p)), \n",
    "        one_hot_vect_to_class(convert_output(ethn_y_p_pred)), \n",
    "        one_hot_vect_to_class(convert_output(ethn_y_u)), \n",
    "        one_hot_vect_to_class(convert_output(ethn_y_u_pred))\n",
    "    ))\n",
    "    \n",
    "\n",
    "def all_ethnicity_equal_difference(\n",
    "    dataset, df_test, model, privileged_group, ethn_y_p, ethn_y_p_pred, metric_fn_list\n",
    "):\n",
    "    scores = [\n",
    "        np.nanmean([\n",
    "            ethnicity_equality_metric(\n",
    "                dataset, \n",
    "                df_test, \n",
    "                e, \n",
    "                model, \n",
    "                privileged_group, \n",
    "                ethn_y_p, \n",
    "                ethn_y_p_pred,\n",
    "                metric_fn\n",
    "            ) \n",
    "            for e in p['ETHNICITIES'].values()\n",
    "        ]) for metric_fn in metric_fn_list\n",
    "    ]\n",
    "    metrics_list = [m.__name__.replace('_', ' ').capitalize() for m in metric_fn_list]\n",
    "    return dict(zip(metrics_list, scores)) # + scores_eodd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05eb61d",
   "metadata": {},
   "source": [
    "### Predict and evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba29e62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_evaluate(df, df_test, model, X_test, y_test, privileged_group, exp_id):\n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    ethn_y_p, ethn_y_p_pred = get_ethnicity_predictions(df, df_test, privileged_group, model) #privileged\n",
    "    \n",
    "    #print(ethn_y_p, ethn_y_p_pred)\n",
    "    \n",
    "    all_ethnicities_f1s = evaluate_all_ethnicities(df, df_test, model)\n",
    "    \n",
    "    ev = dict()\n",
    "    ev['experiment ID'] = exp_id\n",
    "    ev['data sample #'] = round(len(df))\n",
    "    ev['f1'] = f1_score(convert_output(y_test), convert_output(y_pred), average='macro')\n",
    "    ev['f1 variance'] = macro_variance(ev['f1'], list(all_ethnicities_f1s.values()))\n",
    "    #ev.update(all_ethnicities_f1s)\n",
    "    all_parities = all_ethnicity_equal_difference(\n",
    "        df, df_test, model, privileged_group, ethn_y_p, ethn_y_p_pred,\n",
    "        [\n",
    "            disparate_impact_ratio, \n",
    "            statistical_parity_difference, \n",
    "            equal_opportunity_difference,\n",
    "            equal_odd_difference\n",
    "        ]\n",
    "    )\n",
    "    ev.update(all_parities)\n",
    "    #ev['EOR'] = equal_opportunity_difference(convert_output(y_test), convert_output(y_pred))\n",
    "    #print_summary(df, exp_id)\n",
    "    \n",
    "    return ev\n",
    "\n",
    "def compare_model_behaviour(\n",
    "    df_list, df_test_list, \n",
    "    model_list, \n",
    "    X_test_list, y_test_list, \n",
    "    privileged_group_list, \n",
    "    exp_ids\n",
    "):\n",
    "    return [\n",
    "        predict_and_evaluate(\n",
    "            df_list[i], df_test_list[i], \n",
    "            model_list[i], \n",
    "            X_test_list[i], y_test_list[i], \n",
    "            privileged_group_list[i], \n",
    "            exp_ids[i]\n",
    "        ) \n",
    "        for i in range(len(df_list))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050d4c09",
   "metadata": {},
   "source": [
    "### Create pair of self-balanced - imbalanced Z-Fed Framework\n",
    "The trained model will be extracted from the FairServer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "77d43350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_and_train_zfed(\n",
    "    features,\n",
    "    not_features,\n",
    "    dataset,\n",
    "    privileged_group, #numeric\n",
    "    gap=0.05,\n",
    "    max_gap=1,\n",
    "    self_balancing=True,\n",
    "    privileged_group_proportion=0.95     \n",
    "):\n",
    "    zkp_fed_framework = ZKPFEDFramework(\n",
    "        features, not_features, \n",
    "        gap=gap, max_gap=max_gap, \n",
    "        self_balancing=self_balancing\n",
    "    )\n",
    "    unprivileged_proportion = 1 - privileged_group_proportion\n",
    "    agument_fact = 1 if not self_balancing else round(1 / unprivileged_proportion)\n",
    "    df = pd.concat([\n",
    "        create_unbalanced_set(dataset, unprivileged_proportion, privileged_group)\n",
    "    ] * agument_fact)        \n",
    "    df_train, df_test = create_train_test(df)\n",
    "    df_train = df_train.reset_index()\n",
    "    df_test = df_test.reset_index()\n",
    "    X_train, y_train, X_test, y_test = prepare_data(df_train, df_test)\n",
    "\n",
    "    feature_groups = [\n",
    "        {\n",
    "            'ETHNICITY': df_train.iloc[i]['ethnicity'],\n",
    "            'GENDER': df_train.iloc[i]['gender']\n",
    "        } \n",
    "        for i in df_train.index\n",
    "    ]\n",
    "\n",
    "    #train\n",
    "    s = zkp_fed_framework.zkp_fed_training(standard_nn(), X_train, y_train, feature_groups)\n",
    "    return df, df_test, s, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "004cd107",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_compare_pair_balanced_umbalanced(\n",
    "    features,\n",
    "    not_features,\n",
    "    dataset,\n",
    "    privileged_group, #numeric\n",
    "    gap=0.05,\n",
    "    max_gap=1,\n",
    "    privileged_group_proportion=0.95 \n",
    "):\n",
    "    df_b, df_test_b, s_b, X_test_b, y_test_b = create_and_train_zfed(\n",
    "        features,\n",
    "        not_features,\n",
    "        dataset,\n",
    "        privileged_group, #numeric\n",
    "        gap=gap,\n",
    "        max_gap=max_gap,\n",
    "        self_balancing=True,\n",
    "        privileged_group_proportion=privileged_group_proportion\n",
    "    )\n",
    "    \n",
    "    df_u, df_test_u, s_u, X_test_u, y_test_u = create_and_train_zfed(\n",
    "        features,\n",
    "        not_features,\n",
    "        dataset,\n",
    "        privileged_group, #numeric\n",
    "        gap=gap,\n",
    "        max_gap=max_gap,\n",
    "        self_balancing=False,\n",
    "        privileged_group_proportion=privileged_group_proportion\n",
    "    )\n",
    "\n",
    "    metrics = compare_model_behaviour(\n",
    "        [df_b, df_u], [df_test_b, df_test_u],\n",
    "        [s_b.model, s_u.model],\n",
    "        [X_test_b, X_test_u], [y_test_b, y_test_u],\n",
    "        [p['ETHNICITIES'][privileged_group]] * 2,    \n",
    "        ['Self balanced [agumented]', 'Imbalanced']\n",
    "    )\n",
    "    \n",
    "    s_b.plot_hists('Self balanced [agumented]')\n",
    "    s_u.plot_hists('Imbalanced')\n",
    "    \n",
    "    return get_metrics_data(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb9fe94c",
   "metadata": {},
   "source": [
    "### Get results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b43566",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    train_compare_pair_balanced_umbalanced(\n",
    "        features,\n",
    "        not_features,\n",
    "        df,\n",
    "        i, #numeric\n",
    "        gap=0.05,\n",
    "        max_gap=1,\n",
    "        privileged_group_proportion=0.9 \n",
    "    )\n",
    "    for i in range(len(p['ETHNICITIES']))\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176422f5",
   "metadata": {},
   "source": [
    "### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cb34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in results:\n",
    "    display(r)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b3baba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
